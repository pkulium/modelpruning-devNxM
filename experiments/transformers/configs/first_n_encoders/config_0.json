{
    "bert.encoder.layer.0.attention.self.key": {
        "type": "NxM_QUANT",
        "args": {
            "N": 4,
            "M": 2,
            "precision": 8,
            "norm": 2,
            "chunk_size": -1,
            "groups": 1
        }
    },
    "bert.encoder.layer.0.attention.self.value": {
        "type": "NxM_QUANT",
        "args": {
            "N": 4,
            "M": 2,
            "precision": 8,
            "norm": 2,
            "chunk_size": -1,
            "groups": 1
        }
    },
    "bert.encoder.layer.0.attention.self.query": {
        "type": "NxM_QUANT",
        "args": {
            "N": 4,
            "M": 2,
            "precision": 8,
            "norm": 2,
            "chunk_size": -1,
            "groups": 1
        }
    },
    "bert.encoder.layer.0.attention.output.dense": {
        "type": "NxM_QUANT",
        "args": {
            "N": 4,
            "M": 2,
            "precision": 8,
            "norm": 2,
            "chunk_size": -1,
            "groups": 1
        }
    },
    "bert.encoder.layer.0.intermediate.dense": {
        "type": "NxM_QUANT",
        "args": {
            "N": 4,
            "M": 2,
            "precision": 8,
            "norm": 2,
            "chunk_size": -1,
            "groups": 1
        }
    },
    "bert.encoder.layer.0.output.dense": {
        "type": "NxM_QUANT",
        "args": {
            "N": 4,
            "M": 2,
            "precision": 8,
            "norm": 2,
            "chunk_size": -1,
            "groups": 1
        }
    }
}